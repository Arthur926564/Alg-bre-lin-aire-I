\documentclass[11pt]{book}
\usepackage[utf8]{inputenc}	% Para caracteres en español

\usepackage[left=2.75cm,right=2.75cm,top=2cm,bottom=3cm]{geometry}
\usepackage{style}



\begin{document}
\setcounter{section}{8}
\title{Algèbre linéaire I}
\maketitle
\thispagestyle{empty}

\begin{center}

\begin{framedate}
    (10/10/2024)
\end{framedate}
\end{center}
\section{Déterminant et opération élémentaire}
\subsection{Application des opération élémentaire sur le déterminant}
\begin{itemize}
    \item Type I: Interchanger des lignes entre elle ne change pas le déterminant
    \item Type II: changer le signe de la matrice change le signe du déterminant
    \item Type III: En multipliant une ligne par un scalaire $\alpha \in \mathbb{R}$ , le déterminant est aussi multiplier par ce scalaire.

     
\end{itemize}

La preuve est par récurrence, le but est d'initialiser pour des matrice $M_{2\times 2}(\mathbb{R})$ et de le prouver pour des matrice de taille $n+1\times n+1$. 
\\
On suppose donc le résultat vrai pour les matrices de taille $\leq n$ et on passe au cas $M_{n+1\times n+1}(\mathbb{R})$. Ici $n \geq 2$. Comme une opération élémentaire fait intervenir au plus deux lignes, il existe une ligne $L_i$ qui ne change pas. On développe alors det(E*A) selon $L_i$ et on obtien la même formule que $det A$, où les * où $E$ est la matrice d'une opération élémentaire sous-déterminant, det $A_{ij}$ ont été remplacés par det E'$A_{ij}$ où E' est bien une matrice d'opération élémentaire équivalente à E.
\begin{framedremark}
    On écrit parfois $det A = |A|$.
\end{framedremark}
    

\begin{exemple}
Le détérminant  de:
\[\begin{vmatrix}
5 & 4 & 4 & 1\\
2 & 3 & 2 & -2 \\
-5 & -7 & -6 & 9 \\
1 & -2 & -2 & -4
\end{vmatrix}\]
\\
Le but est d'avoir que deux 0 sauf à une endroit sur la ligne 2:
\\
On peut par exemple faire $C_1 - C_3$ et $C_4 + C_3$, on a:
$\begin{vmatrix}
1 & 4 & 4 & 5\\
0 & 3 & 2 & 0 \\
1 & -7 & -6 & 3 \\
3 & -2 & -2 & 2
\end{vmatrix}$ $\to 2\cdot$ $\begin{vmatrix} 
1 & 4 & 2 & 5\\
0 & 3 & 1 & 0 \\
1 & -7 & -3 & 3 \\
3 & -2 & -1 & 2
\end{vmatrix}$
\\
On sort le facteur 2 de $C_3$ et donc il faut multiplier le det avec (Type III), On fait maintenant $C_2 3C_3$:

 \[2\cdot\begin{vmatrix} 
1 & -2 & 2 & 5\\
0 & 0 & 1 & 0 \\
1 & 2 & -3 & 3 \\
3 & 1 & -1 & 2
\end{vmatrix}\]
\newpage

En utilisant les cofacteur on a que:
\[ det A = 2[-0\cdot detA_{21} + 0\cdot detA_{22} -1\cdot \begin{vmatrix} 
1 & -2 & 5\\
1 & 2  & 3 \\
3 & 1  & 2
\end{vmatrix}] = -2\cdot\begin{vmatrix} 
1 & -2 & 5\\
1 & 2  & 3 \\
3 & 1  & 2
\end{vmatrix}\]
On fait le même procédé ($L_2 - L_1$ et $L_3 - 3L_1$):
\[ -2\cdot\begin{vmatrix} 
1 & -2 & 5\\
1 & 2  & 3 \\
3 & 1  & 2
\end{vmatrix} \to -2\cdot\begin{vmatrix} 
1 & -2 & 5\\
0 & 4  & -2 \\
0 & 7  & -13
\end{vmatrix}\]
Ce qui nous donne à la fin:
\[ = -2\cdot 1 \cdot \begin{vmatrix}
    4 & -13 \\
    7 & -13
\end{vmatrix} = -2\cdot 1 [-52 + 14] = 76\]


\end{exemple}
\paragraph{Propriétés du déterminant}
\\

Soit $A$ une matrice de taille $n \times n$ et $\lambda \in \mathbb{R}$ Alors, $det (\lambda A) = \lambda^n \cdot det A $.
\begin{preuve}
    $\lambda \cdot A$ est obtenu de $A$ en effectuant $n$ opération élémentaires de type III (sur chacune des lignes).
    \end{preuve}
    \begin{framedremark}
        Si une ligne de $A$ est combinaison linéaire des autres lignes, alors $det A = 0$.
    \end{framedremark}
    \begin{theorem}
        Une matrice carrée est inversible si et seulement si det$A \neq 0$.
    \end{theorem}
    \begin{preuve}
        Une matrice carré est inversible $n\times n$ iff elle a $n$ pivots iff il existe des opérations élémentaires qui transforment A en une matrice échelonnée avec des pivots, non nuls, sur la diagonale.
        \\
        Le déterminant de cette matrice est le produit des termes de la diagonale, et il est non nul, donc $det A \neq 0$.
    \end{preuve}
    \begin{framedremark}
        Le déterminant a peut être changé de signe ou été multiplié par $\alpha \neq 0$, mais il reste $\neq 0$.
    \end{framedremark}
    
    \begin{theoreme}
        $det(A^t) = detA$
    \end{theoreme}
    \begin{preuve}
        Le développement du déterminant de $A$ selon la première ligne est identique au développement du déterminant de sa transposée selon la première colonne.
    \end{preuve}
    \begin{thm}
        Soit $A$ et $B$ deux matrices $n\times n$. Alors: 
        \\
        \[det(AB) = detA \cdot det B\]

    \end{thm}
    \begin{preuve}
        La preuve se fait en deux parties selon, selon que la matrice A est inversible ou non. 
        \begin{itemize}
            \item Supposons que $A$ soit inversible. Alors nous savons que $A$ peut s'écrire comme produit des matrices élémentaire. La preuve se fait par induction sur le nombre de matrices élémentaires.
            \item Pour initialiser l'induction on doit traiter le as où $A$ est une matrice élémentaire. Il y a donc trois sous-cas.

        \end{itemize}
    \end{preuve}
    \begin{enumerate}
        \item $A = E_{ij}(\lambda)$ est de type I. Comme elle est triangulaire et que sa fiagonale est constituée de 1, on a à $det(E_{ij}(\lambda) = 1$. Il faut encore calculer $det(E_{ij}(\lambda)B)$. \\ det
        \item $A = E_{ij}$, $det E_{ij} = -1$ car c'est $I_n$ avec $L_i$ et $L_j$ élanguées.
        \item $A = E_i(\lambda)$, $det(E_i(\lambda) = \lambda$ (diagonale. $det(E_i(\lambda)\cdot B) = \lambda \cdot detB = det E_{j}(\lambda)\cdot det B$.


    \end{enumerate}
    \textbf{Hypothèse de récurrence} : \[ det(AB) = det A \cdot det B\]
    Pour toutes les matrices $A$ qui sont produits d'au plus $n$ matrices élémentaires.
    \\
    \textbf{Pas de récurrence}. Considérons une matrice $A = E_{n+1} \cdot E_n ...$, qui est le produit de $n + 1$ matrices élémentaires. Nous devons montrer que:
    \[
    det(E_{n+1}\cdot E_n ... E_1 \cdot B) =  det(E_{n+1}\cdot E_n ... E_1)\cdot B    \]
    On sait que $det( E_n ... E_1) = C$ donc $det(E_{n+1}\cdot E_n ... E_1 \cdot B) = det(E_{n+1}) \cdot C$.
    On fait la suite jusqu'à trouver : \[
    det(E_{n+1}\cdot E_n ... E_1)\cdot B
    \]

    \paragraph{$2^{e}$ cas: } $A$ non inversible, Alors par le thèorème précédent, $det A = 0$. Donc $det(A) \cdot det(B) = 0$.\\
    On montre que $A\cdot B $ n'est pas inversible si bien que $det(A\cdot B) = 0$. Si $AB$ est inversible il existe $C$ tel que $(AB)C = I_n$ et $A(BC) = I_n$ mais on sait que $A$ n'est pas inversible, \textbf{Contradiction}.
    \\
    \paragraph{Corollaire} Si $A$ est inversible, alors \[det(A^{-1}) = \frac{1}{det A}\]
    \begin{framedremark}
        Même si en général $AB \neq BA$ on a toujours $det(AB) = (detBA)$ car les deux détérminants donnent $det A \cdot det B = det B \cdot det A$.
    \end{framedremark}
    \begin{framedremark}
        
    
        Attention : \[ det(A + B) \neq det A + det B\]
        Le déterminant n'est pas \textbf{linéaire} comme application, $det : M{n\times n} \to \mathbb{R}$.
    
    \end{framedremark}


    \paragraph{Linéarité du déterminant comme fonction \textbf{d'une colonne}}
    Le déterminant est linéaire comme fonction d'une colonne, pour cela nous devons vérifier:
    \begin{enumerate}
        \item $T(\vec{0}) = 0$ car c'est le déterminant d'une matrice ayant une colonne nulle.
        \item $T(\lambda\vec{x}) = \lambda T(\vec{x})$ car il s'agit d'une opération de type III sur la $j^{eme}$ colonne.
        \item $T(\vec{x}+ \vec{y}) = T(\vec{x}) + T(\vec{y})$ se prouve en développant le déterminant selon la $j^{eme}$ colonne.

    \end{enumerate}


    $A  \in M_{3\times3}(\mathbb{R})$, il faut alors tout développé mais faut juste le faire avec la commutativé et distributivité dans les nombres réels.

    \paragraph{Règles de Charmer}
    \begin{theoreme}
        
    
    Si $det A = ad-bc \neq 0$, le système
    \begin{align*}
        ax + by &= e\\
        cx + dy &= f
    \end{align*}
    A une solution unique (qu'on trouve grâce à la matrice inverse)
    \end{theoreme}
    \\
    
la solution du système est $A^{-1}\vec{b}$: 
\[\frac{1}{ad -bc}\begin{pmatrix}
    d & -b \\
    -c & a
\end{pmatrix}
\begin{pmatrix}
    e \\
    f
\end{pmatrix}\]
Alors : 
\[x = \frac{ed -bf}{ad -b} =  \frac{det\begin{pmatrix}
    e & b \\
    f & d
\end{pmatrix}} {det A}\]
Et:
\[
y = \frac{af - ec}{ad - bc} = \frac{det \begin{pmatrix}
    a & e \\
    c & f
\end{pmatrix}}{det A}
\]
Soit $A$ une matrice carrée \textbf{inversible}. Pour tout vecteur $\vec{b}$ on pose :
\[A_i\vec{b} = (\vec{a_1}... \vec{a}_{i-1} \vec{b} \vec{a}_{i+ 1} ... \vec{a}_n)\]

    La seul solution du système $A\vec{x} = \vec{b}$ est donnée par la formule : 
    \[
    x_i = \frac{detA_i(\vec{b})}{det A}
    \]
\\
\textbf{Preuve}:
\\

\section{Cours mardi 15/10/2024 }



\paragraph{La matrice des cofacteurs} Soit $A$ une matrice $n \times n$ et $A_{ij}$ la matrice $(n-1) \times (n-1)$ obtenue en supprimant la $i^{eme}$ ligne et la $j^{eme}$ colonne de $A$.
\\
\begin{exemple}
    Si on prend la matrice $A = \begin{pmatrix}
        1 & 2 & 3 \\
        4 & 5 & 6 \\
        7 & 8 & 9
    \end{pmatrix}$ et qu'on prend $A_{23}$, alors on enlève la ligne 2 et la colonne 3 ce qui donne que 
    \[ A_{23} = \begin{pmatrix}
        1 & 2 \\
        7 & 8
    \end{pmatrix}\]
    \begin{defn}
        Le \textbf{cofacteur} $C_{ij} = (-1)^{i+j}det A_{ij}$.
    \end{defn}
\end{exemple}
\begin{defn}
    La \textbf{comatrice} ou \textbf{matrice des cofacteurs} de $A$ est la matrice
    \[ComA = (C_{ij})_{n\times n}\]
\end{defn}


\paragraph{Cofacteur et inverse}
Soit $A$ une matrice $n \times n$ inversible. On pose:
\[A_j(\vec{e}_i) = (\vec{a}_1 ... \vec{a}_{j-1} \vec{e}_i \vec{a}_{j+1} ... \vec{a}_n\]
La seule solution du système $A\vec{x} = \vec{e}_i$ est donnée par la formule:
\begin{definition}[Formules de Cramer]
    \begin{equation*}
        x_j = \frac{\det A_j(\vec{e}_i)}{\det A}
    \end{equation*}
\end{definition}


De plus, en développant le déterminant selon la $j^{eme}$ colonne on calcule:
\[\det A_j(\vec{e}_i) = (-1)^{i+j}\det A_{ij}\]

\paragraph{Formule pour l'inverse}
\begin{definition}
    \begin{equation*}
        A^{-1} = \frac{1}{\det A}(ComA)^t
    \end{equation*}
\end{definition}
En français, la matrice inverse est donnée par la transposée des cofacteurs multiplié par l'inverse du déterminant.

\end{document} 
